#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü –≤ –≤–∏–¥–µ–æ
"""

import cv2
import os
import numpy as np
from pathlib import Path

def test_opencv_face_detection(video_path, max_frames=10):
    """–¢–µ—Å—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é OpenCV"""
    print(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –ª–∏—Ü –≤ {video_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º Haar –∫–∞—Å–∫–∞–¥ –¥–ª—è –ª–∏—Ü
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ")
        return False
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps
    
    print(f"üìä –í–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤, {fps:.1f} fps, {duration:.1f} —Å–µ–∫")
    
    faces_detected = 0
    frames_tested = 0
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π 100-–π –∫–∞–¥—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
    frame_step = max(1, total_frames // max_frames)
    
    for frame_num in range(0, total_frames, frame_step):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        ret, frame = cap.read()
        
        if not ret:
            break
            
        frames_tested += 1
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
        faces = face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30)
        )
        
        if len(faces) > 0:
            faces_detected += 1
            print(f"  ‚úÖ –ö–∞–¥—Ä {frame_num}: –Ω–∞–π–¥–µ–Ω–æ {len(faces)} –ª–∏—Ü")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä —Å –ª–∏—Ü–æ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            if faces_detected == 1:
                for (x, y, w, h) in faces:
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.imwrite('test_face_detection.jpg', frame)
                print(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–¥—Ä —Å –ª–∏—Ü–æ–º: test_face_detection.jpg")
        
        if frames_tested >= max_frames:
            break
    
    cap.release()
    
    detection_rate = (faces_detected / frames_tested) * 100 if frames_tested > 0 else 0
    
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"  ‚Ä¢ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frames_tested}")
    print(f"  ‚Ä¢ –ö–∞–¥—Ä–æ–≤ —Å –ª–∏—Ü–∞–º–∏: {faces_detected}")
    print(f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_rate:.1f}%")
    
    return faces_detected > 0

def test_video_audio(video_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—É–¥–∏–æ –≤ –≤–∏–¥–µ–æ"""
    print(f"\nüéµ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ –≤ {video_path}")
    
    cap = cv2.VideoCapture(video_path)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ ffprobe
    import subprocess
    try:
        result = subprocess.run([
            'ffprobe', '-v', 'quiet', '-show_entries', 
            'stream=codec_type', '-of', 'csv=p=0', video_path
        ], capture_output=True, text=True)
        
        streams = result.stdout.strip().split('\n')
        has_video = 'video' in streams
        has_audio = 'audio' in streams
        
        print(f"  ‚Ä¢ –í–∏–¥–µ–æ –ø–æ—Ç–æ–∫: {'‚úÖ' if has_video else '‚ùå'}")
        print(f"  ‚Ä¢ –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫: {'‚úÖ' if has_audio else '‚ùå'}")
        
        return has_audio
        
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É–¥–∏–æ: {e}")
        return False

if __name__ == "__main__":
    video_path = "input_video.mp4"
    
    if not os.path.exists(video_path):
        print(f"‚ùå –í–∏–¥–µ–æ —Ñ–∞–π–ª {video_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        exit(1)
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –≤–∏–¥–µ–æ...")
    
    # –¢–µ—Å—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü
    faces_ok = test_opencv_face_detection(video_path)
    
    # –¢–µ—Å—Ç –∞—É–¥–∏–æ
    audio_ok = test_video_audio(video_path)
    
    print(f"\nüéØ –ò—Ç–æ–≥–æ–≤–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:")
    print(f"  ‚Ä¢ –õ–∏—Ü–∞: {'‚úÖ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã' if faces_ok else '‚ùå –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}")
    print(f"  ‚Ä¢ –ê—É–¥–∏–æ: {'‚úÖ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç' if audio_ok else '‚ùå –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    
    if faces_ok and audio_ok:
        print("üéâ –í–∏–¥–µ–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π!")
    else:
        print("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º")