# –î–û–ü–†–û–° MVP 2.0 - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è Claude Code

## üéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- **–ù–ï –£–ü–†–û–©–ê–¢–¨** —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª - –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã
- **–ö–æ–º–º–∏—Ç–∏—Ç—å** –∫–∞–∂–¥—ã–π —É—Å–ø–µ—à–Ω—ã–π —ç—Ç–∞–ø
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å** Ultralytics YOLO11 —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- **–°–æ—Ö—Ä–∞–Ω—è—Ç—å** –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- **–ü–æ–ª–Ω–∞—è** –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–ù–ï –ò–ó–ú–ï–ù–Ø–¢–¨)

```
dopros-mvp-v2/
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ main.py                      # –ì–ª–∞–≤–Ω—ã–π Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py             # –ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ video_processor.py      # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ emotion_analyzer.py     # –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ audio_processor.py      # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –∏ —Ä–µ—á–∏
‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py     # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ data_aggregator.py      # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ critical_analyzer.py    # –ê–Ω–∞–ª–∏–∑ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ yolo_manager.py         # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ YOLO11 –º–æ–¥–µ–ª—è–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ deepface_wrapper.py     # –û–±–µ—Ä—Ç–∫–∞ DeepFace —Å fallback
‚îÇ   ‚îú‚îÄ‚îÄ speech_analyzer.py      # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ —Ä–µ—á–∏
‚îÇ   ‚îú‚îÄ‚îÄ fer_analyzer.py         # FER –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
‚îÇ   ‚îî‚îÄ‚îÄ simple_analyzer.py      # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ (–ø–æ—Å–ª–µ–¥–Ω–∏–π fallback)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ gpu_manager.py          # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU/CPU
‚îÇ   ‚îú‚îÄ‚îÄ translation.py          # –ü–µ—Ä–µ–≤–æ–¥—ã —ç–º–æ—Ü–∏–π RU/EN
‚îÇ   ‚îú‚îÄ‚îÄ file_manager.py         # –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏ –∏ —Ö–µ—à–∞–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ time_sync.py            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ validators.py           # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ logger.py               # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îú‚îÄ‚îÄ integrations/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ openai_client.py        # OpenAI API (Whisper, GPT-4)
‚îÇ   ‚îú‚îÄ‚îÄ ffmpeg_wrapper.py       # –†–∞–±–æ—Ç–∞ —Å FFmpeg
‚îÇ   ‚îî‚îÄ‚îÄ api_manager.py          # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ–º–∏ API
‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îú‚îÄ‚îÄ videos/                 # –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–∏–¥–µ–æ
‚îÇ   ‚îú‚îÄ‚îÄ audio/                  # –ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
‚îÇ   ‚îú‚îÄ‚îÄ frames/                 # –í—Å–µ –∫–∞–¥—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ faces/                  # –í—ã—Ä–µ–∑–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞
‚îÇ   ‚îú‚îÄ‚îÄ faces_yolo11/           # –ö–∞–¥—Ä—ã —Å –ª—é–¥—å–º–∏ YOLO11
‚îÇ   ‚îú‚îÄ‚îÄ results/                # CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ reports/                # –§–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ cache/                  # –ö—ç—à –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îú‚îÄ‚îÄ demo/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ input_video.mp4    # –î–µ–º–æ –≤–∏–¥–µ–æ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo11n.pt         # YOLO11 nano
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo11n-face.pt    # YOLO11 –¥–ª—è –ª–∏—Ü
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ haarcascade_frontalface.xml
‚îÇ   ‚îî‚îÄ‚îÄ styles/
‚îÇ       ‚îî‚îÄ‚îÄ custom.css          # –°—Ç–∏–ª–∏ –¥–ª—è Streamlit
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ test_compatibility.py   # –¢–µ—Å—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    ‚îú‚îÄ‚îÄ test_pipeline.py        # –¢–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞
    ‚îú‚îÄ‚îÄ test_models.py          # –¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π
    ‚îî‚îÄ‚îÄ fixtures/               # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
```

## üìù –ü–†–û–ú–ü–¢–´ –î–õ–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–ò

### –ü–†–û–ú–ü–¢ 1: –ë–∞–∑–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
```
–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ –î–û–ü–†–û–° MVP 2.0 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ –¥–æ–ø—Ä–æ—Å–æ–≤.

requirements.txt –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –í–°–ï –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
- streamlit
- ultralytics
- opencv-python
- opencv-contrib-python
- deepface
- tensorflow>=2
- torch>=2.1.0
- torchvision>=0.16.0
- pandas>=2.1.0
- numpy>=1.24.0
- plotly>=5.18.0
- openai>=1.10.0
- librosa>=0.10.1
- soundfile>=0.12.1
- pyyaml>=6.0.1
- python-dotenv>=1.0.0
- tqdm>=4.66.0
- Pillow>=10.2.0
- fer>=22.5.0
- scikit-learn>=1.3.0
- scipy>=1.11.0
- matplotlib>=3.8.0
- seaborn>=0.13.0
- python-ffmpeg>=2.0.0
- colorama>=0.4.6
- psutil>=5.9.0

.gitignore –¥–æ–ª–∂–µ–Ω –∏—Å–∫–ª—é—á–∞—Ç—å:
- .env
- *.pt (–º–æ–¥–µ–ª–∏)
- storage/* (–∫—Ä–æ–º–µ .gitkeep)
- __pycache__
- *.pyc
- .DS_Store
- *.log

–°–æ–∑–¥–∞–π config.yaml —Å –ü–û–õ–ù–´–ú–ò –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ (–Ω–µ —É–ø—Ä–æ—â–∞–π):
```yaml
app:
  name: "–î–û–ü–†–û–° MVP 2.0"
  version: "2.0.0"
  language: "ru"
  debug: false

processing:
  video:
    frame_skip: 15  # –ö–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä
    min_frames: 10  # –ú–∏–Ω–∏–º—É–º –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    output_format: "jpg"
    quality: 95
    max_resolution: [1920, 1080]
    
  audio:
    sample_rate: 16000
    channels: 1
    format: "wav"
    segment_length: 30  # —Å–µ–∫—É–Ω–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
    
  models:
    yolo:
      version: "11"
      models:
        detection: "yolo11n.pt"
        face: "yolo11n-face.pt"
        emotion: "yolo11n-emotion.pt"
      confidence_threshold: 0.5
      iou_threshold: 0.45
      max_detections: 100
      device: "auto"  # auto, cpu, cuda, mps
      force_cpu: false
      
    deepface:
      enabled: true
      backend: "opencv"
      enforce_detection: false
      detector_backend: "opencv"
      model: "Emotion"
      
    fer:
      enabled: true
      mtcnn: true
      
    speech:
      model: "base"
      emotions: ["angry", "disgust", "fear", "happy", "neutral", "sad", "surprise"]
      
    whisper:
      model: "whisper-1"
      language: "ru"
      temperature: 0
      
    gpt:
      model: "gpt-4-turbo-preview"
      max_tokens: 4000
      temperature: 0.3

storage:
  base_dir: "storage"
  videos_dir: "storage/videos"
  audio_dir: "storage/audio"
  frames_dir: "storage/frames"
  faces_dir: "storage/faces"
  faces_yolo11_dir: "storage/faces_yolo11"
  results_dir: "storage/results"
  reports_dir: "storage/reports"
  cache_dir: "storage/cache"
  
  cleanup:
    enabled: true
    max_age_days: 7
    max_size_gb: 50

analysis:
  emotion_categories:
    basic: ["–∑–ª–æ—Å—Ç—å", "–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ", "—Å—Ç—Ä–∞—Ö", "—Å—á–∞—Å—Ç—å–µ", "–≥—Ä—É—Å—Ç—å", "—É–¥–∏–≤–ª–µ–Ω–∏–µ", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å"]
    specialized: ["—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ", "–¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç", "–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–±—Ä–æ–≤–µ–π", "–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–≥–ª–∞–∑", "–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_—Ä—Ç–∞"]
    
  critical_detection:
    rapid_change_threshold: 3  # –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥
    confidence_threshold: 0.7
    time_window: 5  # —Å–µ–∫—É–Ω–¥
    
  report:
    formats: ["csv", "json", "html", "pdf"]
    include_graphs: true
    include_timeline: true
    include_transitions: true
    include_statistics: true
    include_insights: true

api:
  openai:
    key: "${OPENAI_API_KEY}"
    timeout: 60
    max_retries: 3
    
  rate_limits:
    whisper: 50  # –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
    gpt: 60  # –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É

performance:
  max_workers: 4
  batch_size: 32
  memory_limit_gb: 8
  gpu_memory_fraction: 0.8
  enable_caching: true
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "dopros.log"
  max_size_mb: 100
  backup_count: 5
```

–°–æ–∑–¥–∞–π .env.example:
```
OPENAI_API_KEY=your_api_key_here
HUGGINGFACE_TOKEN=optional_token
LOG_LEVEL=INFO
```

–°–æ–∑–¥–∞–π –≤—Å–µ –ø–∞–ø–∫–∏ —Å .gitkeep —Ñ–∞–π–ª–∞–º–∏ –≤ storage –ø–æ–¥–ø–∞–ø–∫–∞—Ö.
```

### –ü–†–û–ú–ü–¢ 2: GPU/CPU –º–µ–Ω–µ–¥–∂–µ—Ä —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
```
–°–æ–∑–¥–∞–π utils/gpu_manager.py –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ —Å –ü–û–õ–ù–´–ú —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º:

1. –ö–ª–∞—Å—Å GPUManager –¥–æ–ª–∂–µ–Ω:
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA, MPS (Mac), DirectML (Windows)
   - –ü—Ä–æ–≤–µ—Ä—è—Ç—å –≤–µ—Ä—Å–∏—é CUDA –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å PyTorch
   - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É torchvision::nms –¥–ª—è YOLO
   - –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –Ω–∞ CPU –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ GPU

2. –ú–µ—Ç–æ–¥—ã:
   - setup_device(force_cpu=False, preferred_gpu=0) - –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
   - test_cuda_nms() - —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è YOLO NMS
   - get_device_info() - –ø–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
   - get_memory_info() - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
   - clear_cache() - –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ GPU
   - benchmark_device() - —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
   - auto_select_device() - –∞–≤—Ç–æ–≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

3. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –º–µ–Ω–µ–¥–∂–µ—Ä—ã:
   - with gpu_manager.device_context('cuda:1') - –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ
   - with gpu_manager.memory_limit(4096) - –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏

4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫ YOLO:
   - RuntimeError —Å torchvision::nms
   - CUDA out of memory
   - CUDNN errors
   
5. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π

6. Singleton –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –µ–¥–∏–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
```python
gpu_manager = GPUManager.get_instance()
device = gpu_manager.setup_device()
if gpu_manager.test_cuda_nms():
    print("CUDA NMS —Ä–∞–±–æ—Ç–∞–µ—Ç")
info = gpu_manager.get_device_info()
```
```

### –ü–†–û–ú–ü–¢ 3: YOLO11 –º–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Ultralytics
```
–°–æ–∑–¥–∞–π models/yolo_manager.py –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é Ultralytics –¥–ª—è YOLO11:

1. –ö–ª–∞—Å—Å YOLO11Manager —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:
   - –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π yolo11n/s/m/l/x.pt
   - –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–∏—Ü –∏ —ç–º–æ—Ü–∏–π
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤: detect, segment, classify, pose
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç

2. –ú–µ—Ç–æ–¥ extract_frames_with_people():
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å model.predict() —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
   - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: conf, iou, imgsz, max_det, classes
   - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∞ person (class_id=0)
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –≤ –∏–º–µ–Ω–∏
   - –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å boxes, masks, keypoints –µ—Å–ª–∏ –µ—Å—Ç—å
   
3. –ú–µ—Ç–æ–¥ detect_faces():
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ª–∏—Ü
   - –í—ã—Ä–µ–∑–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª–∏—Ü
   - Tracking –ª–∏—Ü –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ (model.track)
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (confidence, bbox, track_id)

4. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:
   - model.predict(source=image_list, stream=True)
   - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
   - –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å tqdm

5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ CUDA:
   ```python
   try:
       results = model.predict(frame, device='cuda')
   except RuntimeError as e:
       if "torchvision::nms" in str(e):
           model.to('cpu')
           results = model.predict(frame, device='cpu')
   ```

6. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
   - results.save() –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
   - results.to_df() –¥–ª—è pandas DataFrame
   - results.to_json() –¥–ª—è JSON

7. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:
   ```python
   model = YOLO('yolo11n.pt')
   model.info()  # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
   model.fuse()  # –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è inference
   ```

8. –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏:
   - model.val() –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
   - –ú–µ—Ç—Ä–∏–∫–∏: mAP, precision, recall

–ò—Å–ø–æ–ª—å–∑—É–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π API –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Å–≤–æ–∏ –º–µ—Ç–æ–¥—ã.
```

### –ü–†–û–ú–ü–¢ 4: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç–º–æ—Ü–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
```
–°–æ–∑–¥–∞–π core/emotion_analyzer.py —Å –ü–û–õ–ù–û–ô —Å–∏—Å—Ç–µ–º–æ–π –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π:

1. –ö–ª–∞—Å—Å MultiModalEmotionAnalyzer —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π:
   - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: DeepFace (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
   - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: FER (Face Emotion Recognition)
   - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: YOLO11 —Å –º–æ–¥–µ–ª—å—é —ç–º–æ—Ü–∏–π
   - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4: OpenCV + –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞

2. –ú–µ—Ç–æ–¥ analyze_frame() –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å:
   ```python
   {
       'emotion': '–∑–ª–æ—Å—Ç—å',
       'emotion_en': 'angry',
       'confidence': 0.85,
       'all_emotions': {
           '–∑–ª–æ—Å—Ç—å': 0.85,
           '—Å—Ç—Ä–∞—Ö': 0.10,
           '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å': 0.05
       },
       'method': 'deepface',
       'face_bbox': [x1, y1, x2, y2],
       'timestamp': 12.5,
       'frame_number': 375
   }
   ```

3. DeepFace –æ–±–µ—Ä—Ç–∫–∞:
   - try/except –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
   - –í—Å–µ 7 –±–∞–∑–æ–≤—ã—Ö —ç–º–æ—Ü–∏–π
   - enforce_detection=False –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ª–∏—Ü

4. FER –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä:
   - MTCNN –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü
   - top_emotion –∏ –≤—Å–µ scores
   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –ø–æ—Ç–æ–∫–∞

5. YOLO11 —ç–º–æ—Ü–∏–∏:
   - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –¥–ª—è –¥–æ–ø—Ä–æ—Å–æ–≤
   - –ú–∏–∫—Ä–æ–≤—ã—Ä–∞–∂–µ–Ω–∏—è (–±—Ä–æ–≤–∏, –≥–ª–∞–∑–∞, —Ä–æ—Ç)
   - –£—Ä–æ–≤–µ–Ω—å –∫–æ–º—Ñ–æ—Ä—Ç–∞/–¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç–∞

6. –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (fallback):
   - Haar Cascade –¥–ª—è –ª–∏—Ü
   - –ê–Ω–∞–ª–∏–∑ –ø–æ —Ü–≤–µ—Ç–æ–≤—ã–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞–º
   - –ë–∞–∑–æ–≤—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

7. –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑:
   - detect_emotion_transitions() - –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —ç–º–æ—Ü–∏—è–º–∏
   - find_rapid_changes() - —Ä–µ–∑–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
   - calculate_emotion_stability() - —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è

8. Batch processing:
   - –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –∫–∞–¥—Ä–æ–≤
   - –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ ThreadPoolExecutor
   - –ü—Ä–æ–≥—Ä–µ—Å—Å —Å tqdm

9. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ storage/cache
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ö–µ—à—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
   - –ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞

10. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≤–∏–¥–µ–æ –≤—Ä–µ–º–µ–Ω–µ–º:
    - –¢–æ—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    - –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
    - –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Ä–µ–∑–∫–∏—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
```

### –ü–†–û–ú–ü–¢ 5: –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —ç–º–æ—Ü–∏–π —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
```
–°–æ–∑–¥–∞–π utils/translation.py —Å –ü–û–õ–ù–û–ô —Å–∏—Å—Ç–µ–º–æ–π –ø–µ—Ä–µ–≤–æ–¥–∞:

1. –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –í–°–ï–• —Ç–∏–ø–æ–≤ —ç–º–æ—Ü–∏–π:
```python
DEEPFACE_EMOTIONS = {
    'angry': '–∑–ª–æ—Å—Ç—å',
    'disgust': '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ',
    'fear': '—Å—Ç—Ä–∞—Ö',
    'happy': '—Å—á–∞—Å—Ç—å–µ',
    'sad': '–≥—Ä—É—Å—Ç—å',
    'surprise': '—É–¥–∏–≤–ª–µ–Ω–∏–µ',
    'neutral': '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å'
}

FER_EMOTIONS = {
    'angry': '–∑–ª–æ—Å—Ç—å',
    'disgust': '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ',
    'fear': '—Å—Ç—Ä–∞—Ö',
    'happy': '—Å—á–∞—Å—Ç—å–µ',
    'sad': '–≥—Ä—É—Å—Ç—å',
    'surprise': '—É–¥–∏–≤–ª–µ–Ω–∏–µ',
    'neutral': '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å'
}

YOLO_SPECIALIZED = {
    'comfortable': '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ',
    'uncomfortable': '–¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç',
    'tension_brow': '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–±—Ä–æ–≤–µ–π',
    'tension_eye': '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–≥–ª–∞–∑',
    'tension_mouth': '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_—Ä—Ç–∞',
    'stress': '—Å—Ç—Ä–µ—Å—Å',
    'anxiety': '—Ç—Ä–µ–≤–æ–∂–Ω–æ—Å—Ç—å',
    'defensive': '–∑–∞—â–∏—Ç–Ω–∞—è_—Ä–µ–∞–∫—Ü–∏—è',
    'aggressive': '–∞–≥—Ä–µ—Å—Å–∏—è',
    'deceptive': '–ø–æ–ø—ã—Ç–∫–∞_–æ–±–º–∞–Ω–∞'
}

SPEECH_EMOTIONS = {
    'angry': '–∑–ª–æ—Å—Ç—å',
    'disgust': '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ', 
    'fearful': '—Å—Ç—Ä–∞—Ö',
    'happy': '—Å—á–∞—Å—Ç—å–µ',
    'neutral': '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å',
    'sad': '–≥—Ä—É—Å—Ç—å',
    'surprised': '—É–¥–∏–≤–ª–µ–Ω–∏–µ',
    'calm': '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ',
    'excited': '–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ',
    'frustration': '—Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è'
}
```

2. –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –¥–ª—è –ö–ê–ñ–î–û–ô —ç–º–æ—Ü–∏–∏:
```python
EMOTION_COLORS = {
    '–∑–ª–æ—Å—Ç—å': '#FF4444',
    '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ': '#9ACD32',
    '—Å—Ç—Ä–∞—Ö': '#800080',
    '—Å—á–∞—Å—Ç—å–µ': '#FFD700',
    '–≥—Ä—É—Å—Ç—å': '#4169E1',
    '—É–¥–∏–≤–ª–µ–Ω–∏–µ': '#FF8C00',
    '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å': '#808080',
    '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ': '#90EE90',
    '–¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç': '#8B0000',
    '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–±—Ä–æ–≤–µ–π': '#FF6347',
    '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_–≥–ª–∞–∑': '#DC143C',
    '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ_—Ä—Ç–∞': '#B22222',
    '—Å—Ç—Ä–µ—Å—Å': '#FF1493',
    '—Ç—Ä–µ–≤–æ–∂–Ω–æ—Å—Ç—å': '#9400D3',
    '–∑–∞—â–∏—Ç–Ω–∞—è_—Ä–µ–∞–∫—Ü–∏—è': '#4B0082',
    '–∞–≥—Ä–µ—Å—Å–∏—è': '#8B0000',
    '–ø–æ–ø—ã—Ç–∫–∞_–æ–±–º–∞–Ω–∞': '#2F4F4F',
    '–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ': '#FF69B4',
    '—Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è': '#CD5C5C'
}
```

3. –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:
```python
EMOTION_DESCRIPTIONS = {
    '–∑–ª–æ—Å—Ç—å': {
        'short': '–°–æ—Å—Ç–æ—è–Ω–∏–µ –≥–Ω–µ–≤–∞ –∏–ª–∏ —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏—è',
        'detailed': '–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–µ–µ—Å—è –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å—é, —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ–º. –ú–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—é –∏–ª–∏ –∑–∞—â–∏—Ç–Ω—É—é —Ä–µ–∞–∫—Ü–∏—é.',
        'indicators': ['—Å–∂–∞—Ç—ã–µ –≥—É–±—ã', '–Ω–∞—Ö–º—É—Ä–µ–Ω–Ω—ã–µ –±—Ä–æ–≤–∏', '–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–∞—è —á–µ–ª—é—Å—Ç—å'],
        'interrogation_meaning': '–í–æ–∑–º–æ–∂–Ω–∞—è –∑–∞—â–∏—Ç–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ –Ω–µ—É–¥–æ–±–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã'
    },
    # ... –¥–ª—è –∫–∞–∂–¥–æ–π —ç–º–æ—Ü–∏–∏
}
```

4. –§—É–Ω–∫—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:
   - translate_emotion(emotion, source='deepface', target_lang='ru')
   - translate_batch(emotions_list, source='deepface')
   - get_emotion_color(emotion, intensity=1.0) - —Å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å—é
   - get_emotion_description(emotion, detail_level='short')
   - get_interrogation_interpretation(emotion) - –¥–ª—è –¥–æ–ø—Ä–æ—Å–æ–≤

5. –û–±—Ä–∞—Ç–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥:
   - reverse_translate(russian_emotion)
   - get_original_emotion(translated, source)

6. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤:
   - format_for_report(emotion_data)
   - create_emotion_legend() - –ª–µ–≥–µ–Ω–¥–∞ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
   - get_emotion_emoji(emotion) - —ç–º–æ–¥–∑–∏ –¥–ª—è UI
```

### –ü–†–û–ú–ü–¢ 6: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç–º–æ—Ü–∏–π –≤ —Ä–µ—á–∏
```
–°–æ–∑–¥–∞–π models/speech_analyzer.py –¥–ª—è –ü–û–õ–ù–û–ì–û –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏:

1. –ö–ª–∞—Å—Å AdvancedSpeechEmotionAnalyzer:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ librosa –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   - MFCC, —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, pitch, energy
   - –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
   - Fallback –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã

2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:
```python
def extract_features(audio_segment):
    features = {
        'mfcc': librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13),
        'spectral_centroid': librosa.feature.spectral_centroid(y=audio, sr=sr),
        'zero_crossing_rate': librosa.feature.zero_crossing_rate(audio),
        'spectral_rolloff': librosa.feature.spectral_rolloff(y=audio, sr=sr),
        'pitch': librosa.piptrack(y=audio, sr=sr),
        'energy': np.sum(audio**2) / len(audio),
        'tempo': librosa.beat.tempo(y=audio, sr=sr)
    }
    return features
```

3. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ:
   - –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ (1-3 —Å–µ–∫—É–Ω–¥—ã)
   - –î–µ—Ç–µ–∫—Ü–∏—è –ø–∞—É–∑ –∏ silence removal
   - Voice Activity Detection (VAD)
   - –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≤–∏–¥–µ–æ –∫–∞–¥—Ä–∞–º–∏

4. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —ç–º–æ—Ü–∏–π:
   - 7 –±–∞–∑–æ–≤—ã—Ö —ç–º–æ—Ü–∏–π + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —ç–º–æ—Ü–∏–∏
   - –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏

5. –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–∏–≤—è–∑–∫–∞:
```python
{
    'start_time': 10.5,
    'end_time': 13.2,
    'emotion': '—Å—Ç—Ä–∞—Ö',
    'confidence': 0.78,
    'all_emotions': {...},
    'audio_features': {...},
    'intensity': 0.65,
    'voice_quality': 'trembling'
}
```

6. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Å–æ–¥–∏–∫–∏:
   - –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–Ω–∞ –≥–æ–ª–æ—Å–∞
   - –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏
   - –ì—Ä–æ–º–∫–æ—Å—Ç—å –∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å
   - –î—Ä–æ–∂–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞

7. –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π:
   - –†–µ–∑–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
   - –ù–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—É–∑—ã
   - –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç—Ä–µ—Å—Å–∞ –≤ –≥–æ–ª–æ—Å–µ

8. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –≤–∏–¥–µ–æ:
   - –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ
   - –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π
   - –û–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏

9. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
   - CSV —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
   - JSON –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
   - –ê—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∫–∞–º–∏
```

### –ü–†–û–ú–ü–¢ 7: –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∞—É–¥–∏–æ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
```
–°–æ–∑–¥–∞–π core/audio_processor.py —Å–æ –í–°–ï–ú–ò –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏:

1. –ö–ª–∞—Å—Å CompleteAudioProcessor:
   - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ (FFmpeg)
   - –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (Whisper API)
   - –£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (GPT-4)
   - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≥–æ–≤–æ—Ä—è—â–∏—Ö
   - –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è

2. FFmpeg –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:
```python
def extract_audio(video_path):
    # –ü–æ–∏—Å–∫ FFmpeg –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
    ffmpeg_paths = [
        'ffmpeg',
        shutil.which('ffmpeg'),
        '/usr/local/bin/ffmpeg',
        'C:\\ffmpeg\\bin\\ffmpeg.exe',
        os.path.expanduser('~/ffmpeg/ffmpeg')
    ]
    
    # –ö–æ–º–∞–Ω–¥–∞ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    cmd = [
        ffmpeg_path,
        '-i', video_path,
        '-vn',  # –±–µ–∑ –≤–∏–¥–µ–æ
        '-acodec', 'pcm_s16le',
        '-ar', '16000',
        '-ac', '1',
        '-y',  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å
        output_path
    ]
```

3. Whisper —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏:
```python
def transcribe_with_timestamps(audio_path):
    response = openai.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        response_format="verbose_json",
        timestamp_granularities=["segment", "word"],
        language="ru"
    )
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
```

4. GPT-4 –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞:
   - enhance_transcript() - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è
   - identify_speakers() - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–≤–æ—Ä—è—â–∏—Ö
   - extract_key_moments() - –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
   - analyze_content() - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä–µ–ø–ª–∏–∫–∏:
```python
def split_dialogue(transcript):
    return {
        'interrogator': [
            {'text': '...', 'start': 0.0, 'end': 5.2},
            ...
        ],
        'subject': [
            {'text': '...', 'start': 5.3, 'end': 12.1},
            ...
        ]
    }
```

6. –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ–ø—Ä–æ—Å–∞:
   - –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
   - –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
   - –û—Ü–µ–Ω–∫–∞ –∫–æ–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏

7. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≤–∏–¥–µ–æ:
   - –ü—Ä–∏–≤—è–∑–∫–∞ —Ä–µ–ø–ª–∏–∫ –∫ –∫–∞–¥—Ä–∞–º
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç–º–æ—Ü–∏–π –∏ —Å–ª–æ–≤
   - –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å–æ–±—ã—Ç–∏–π

8. –§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞:
   - SRT —Å—É–±—Ç–∏—Ç—Ä—ã —Å —ç–º–æ—Ü–∏—è–º–∏
   - –¢–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç–µ–Ω–æ–≥—Ä–∞–º–º–∞
   - JSON —Å –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π
   - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç
```

### –ü–†–û–ú–ü–¢ 8: OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
```
–°–æ–∑–¥–∞–π integrations/openai_client.py —Å–æ –í–°–ï–ú–ò –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ API:

1. –ö–ª–∞—Å—Å OpenAIIntegration —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π:
   - –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–∞ –∏–∑ .env
   - Retry –ª–æ–≥–∏–∫–∞ —Å exponential backoff
   - Rate limiting
   - –¢–æ–∫–µ–Ω counting –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
   - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

2. Whisper –º–µ—Ç–æ–¥—ã:
```python
def transcribe_audio(self, audio_path, **kwargs):
    # –° –ø–æ–≤—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    for attempt in range(self.max_retries):
        try:
            with open(audio_path, 'rb') as audio_file:
                response = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ru",
                    response_format="verbose_json",
                    timestamp_granularities=["segment", "word"],
                    **kwargs
                )
            return self._process_whisper_response(response)
        except openai.RateLimitError:
            time.sleep(2 ** attempt)
```

3. GPT-4 –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ –¥–ª—è –¥–æ–ø—Ä–æ—Å–æ–≤:
```python
PROMPTS = {
    'enhance_transcript': '''
        –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–æ–ø—Ä–æ—Å–∞.
        –î–æ–±–∞–≤—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.
        –†–∞–∑–¥–µ–ª–∏ –Ω–∞ —Ä–µ–ø–ª–∏–∫–∏ –¥–æ–ø—Ä–∞—à–∏–≤–∞—é—â–µ–≥–æ –∏ –¥–æ–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ.
        –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ —Å–ª–æ–≤–∞ –∏ —Å–º—ã—Å–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    ''',
    
    'analyze_psychology': '''
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ.
        –ù–∞–π–¥–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç—Ä–µ—Å—Å–∞, –æ–±–º–∞–Ω–∞, —É–∫–ª–æ–Ω–µ–Ω–∏—è.
        –û–ø—Ä–µ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã.
        –û—Ü–µ–Ω–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏–π.
    ''',
    
    'extract_insights': '''
        –ù–∞ –æ—Å–Ω–æ–≤–µ —ç–º–æ—Ü–∏–π –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏:
        1. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —ç–ø–∏–∑–æ–¥—ã —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥–µ—Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        2. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è
        3. –ü–æ–ø—ã—Ç–∫–∏ —É–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –æ—Ç–≤–µ—Ç–æ–≤
        4. –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ –ø–æ–∫–∞–∑–∞–Ω–∏—è—Ö
        5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –¥–æ–ø—Ä–æ—Å–∞
    '''
}
```

4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥:
```python
def get_structured_analysis(self, data):
    response = self.client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=[...],
        response_format={"type": "json_object"},
        functions=[{
            "name": "analyze_interrogation",
            "parameters": {
                "type": "object",
                "properties": {
                    "critical_moments": {"type": "array"},
                    "deception_indicators": {"type": "array"},
                    "stress_level": {"type": "number"},
                    "cooperation_level": {"type": "number"},
                    "key_findings": {"type": "array"},
                    "recommendations": {"type": "array"}
                }
            }
        }]
    )
```

5. –¢–æ–∫–µ–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:
   - –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
   - –†–∞–∑–±–∏–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
   - –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤

6. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ:
   - –•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ storage/cache
   - TTL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤

7. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
   - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
   - –ü–æ–¥—Å—á–µ—Ç –∑–∞—Ç—Ä–∞—Ç
   - –ê–ª–µ—Ä—Ç—ã –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤
```

### –ü–†–û–ú–ü–¢ 9: –ü–æ–ª–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤
```
–°–æ–∑–¥–∞–π core/report_generator.py —Å–æ –í–°–ï–ú–ò —Ç–∏–ø–∞–º–∏ –æ—Ç—á–µ—Ç–æ–≤:

1. –ö–ª–∞—Å—Å ComprehensiveReportGenerator:
   - 5 —Ñ–æ—Ä–º–∞—Ç–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∞ (CSV, JSON, HTML, PDF, DOCX)
   - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ Plotly
   - –í—Ä–µ–º–µ–Ω–Ω—ã–µ —à–∫–∞–ª—ã
   - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–¥–∫–∏
   - –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã

2. CSV –æ—Ç—á–µ—Ç—ã (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ):
```python
def generate_csv_reports(self):
    reports = {
        'emotions_timeline.csv': self._create_emotions_timeline(),
        'transitions.csv': self._create_transitions_report(),
        'speech_emotions.csv': self._create_speech_report(),
        'critical_moments.csv': self._create_critical_moments(),
        'correlation_matrix.csv': self._create_correlation_matrix(),
        'summary_statistics.csv': self._create_statistics()
    }
```

3. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞:
```python
def create_interactive_timeline(self):
    fig = go.Figure()
    
    # –í–∏–¥–µ–æ —ç–º–æ—Ü–∏–∏
    fig.add_trace(go.Scatter(
        x=video_timestamps,
        y=video_emotions,
        mode='lines+markers',
        name='–≠–º–æ—Ü–∏–∏ –ª–∏—Ü–∞',
        line=dict(color='blue', width=2),
        hovertemplate='%{y}<br>–í—Ä–µ–º—è: %{x:.1f}—Å<br>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: %{customdata:.2f}'
    ))
    
    # –ê—É–¥–∏–æ —ç–º–æ—Ü–∏–∏
    fig.add_trace(go.Scatter(
        x=audio_timestamps,
        y=audio_emotions,
        mode='lines+markers',
        name='–≠–º–æ—Ü–∏–∏ —Ä–µ—á–∏',
        line=dict(color='red', width=2)
    ))
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã
    for moment in critical_moments:
        fig.add_vline(x=moment['time'], line_dash="dash", 
                     annotation_text=moment['description'])
```

4. –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —ç–º–æ—Ü–∏–π:
```python
def create_emotion_heatmap(self):
    # –ú–∞—Ç—Ä–∏—Ü–∞ —ç–º–æ—Ü–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    fig = px.imshow(
        emotion_matrix,
        labels=dict(x="–í—Ä–µ–º—è", y="–≠–º–æ—Ü–∏—è", color="–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å"),
        x=time_labels,
        y=emotion_labels,
        color_continuous_scale="RdBu_r"
    )
```

5. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:
   - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π (pie charts)
   - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ
   - –ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (transition matrix)
   - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

6. HTML –æ—Ç—á–µ—Ç —Å –ø–æ–ª–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π:
```python
def generate_html_report(self):
    template = '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>–î–û–ü–†–û–° MVP - –û—Ç—á–µ—Ç</title>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        <style>{custom_css}</style>
    </head>
    <body>
        <h1>–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–ø—Ä–æ—Å–∞</h1>
        
        <section id="summary">
            <h2>–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞</h2>
            {summary_content}
        </section>
        
        <section id="timeline">
            <h2>–í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —ç–º–æ—Ü–∏–π</h2>
            {timeline_plot}
        </section>
        
        <section id="critical">
            <h2>–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã</h2>
            {critical_moments_table}
        </section>
        
        <section id="transcript">
            <h2>–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∞–Ω–∞–ª–∏–∑–æ–º</h2>
            {annotated_transcript}
        </section>
        
        <section id="insights">
            <h2>–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã</h2>
            {gpt_insights}
        </section>
    </body>
    </html>
    '''
```

7. PDF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ reportlab –∏–ª–∏ weasyprint
   - –í–∫–ª—é—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
   - –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
   - –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—è

8. –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:
   - JSON —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
   - Pickle –¥–ª—è Python –æ–±—ä–µ–∫—Ç–æ–≤
   - Excel —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ª–∏—Å—Ç–∞–º–∏
```

### –ü–†–û–ú–ü–¢ 10: –ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –ø–æ–ª–Ω–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–µ–π
```
–°–æ–∑–¥–∞–π core/pipeline.py - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –í–°–ï–• –ø—Ä–æ—Ü–µ—Å—Å–æ–≤:

1. –ö–ª–∞—Å—Å MasterPipeline —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º:
```python
class MasterPipeline:
    def __init__(self, config_path='config.yaml'):
        self.config = self._load_config(config_path)
        self.gpu_manager = GPUManager.get_instance()
        self.yolo_manager = YOLO11Manager(self.config)
        self.emotion_analyzer = MultiModalEmotionAnalyzer(self.config)
        self.audio_processor = CompleteAudioProcessor(self.config)
        self.speech_analyzer = AdvancedSpeechEmotionAnalyzer(self.config)
        self.data_aggregator = DataAggregator(self.config)
        self.report_generator = ComprehensiveReportGenerator(self.config)
        self.openai_client = OpenAIIntegration(self.config)
        
    def process_video(self, video_path, options=None):
        # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏
```

2. –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å checkpoints:
```python
stages = [
    ('validate_input', self._validate_input),
    ('setup_session', self._setup_session),
    ('extract_frames', self._extract_frames),
    ('detect_faces', self._detect_faces),
    ('analyze_emotions', self._analyze_emotions),
    ('extract_audio', self._extract_audio),
    ('transcribe_audio', self._transcribe_audio),
    ('analyze_speech', self._analyze_speech),
    ('synchronize_data', self._synchronize_data),
    ('detect_critical', self._detect_critical_moments),
    ('generate_insights', self._generate_insights),
    ('create_reports', self._create_reports)
]

for stage_name, stage_func in stages:
    try:
        checkpoint_file = f"cache/{session_id}/{stage_name}.pkl"
        if os.path.exists(checkpoint_file) and not force_reprocess:
            results[stage_name] = load_checkpoint(checkpoint_file)
        else:
            results[stage_name] = stage_func(previous_results)
            save_checkpoint(results[stage_name], checkpoint_file)
        
        if progress_callback:
            progress_callback(stage_index / total_stages, stage_name)
            
    except Exception as e:
        self._handle_stage_error(stage_name, e, results)
```

3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ:
```python
with ThreadPoolExecutor(max_workers=self.config['performance']['max_workers']) as executor:
    futures = {
        'video': executor.submit(self._process_video_stream, video_path),
        'audio': executor.submit(self._process_audio_stream, video_path)
    }
    
    for name, future in futures.items():
        results[name] = future.result(timeout=timeout)
```

4. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é:
```python
def _manage_memory(self):
    if psutil.virtual_memory().percent > 80:
        self._cleanup_cache()
        gc.collect()
        if self.gpu_manager.device != 'cpu':
            torch.cuda.empty_cache()
```

5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º:
```python
def _handle_stage_error(self, stage, error, results):
    self.logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ {stage}: {error}")
    
    if stage in self.critical_stages:
        raise PipelineError(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {stage}")
    
    # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback
    if stage in self.fallback_methods:
        results[stage] = self.fallback_methods[stage](results)
    else:
        results[stage] = None
        results['errors'].append({
            'stage': stage,
            'error': str(error),
            'timestamp': datetime.now()
        })
```

6. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ:
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
   - –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–µ—Ä–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
   - –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫—ç—à–µ–π

7. –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:
```python
metrics = {
    'processing_time': {},
    'memory_usage': {},
    'gpu_usage': {},
    'api_calls': {},
    'errors': []
}
```

8. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ —ç–∫—Å–ø–æ—Ä—Ç:
```python
def finalize(self, results):
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤
    # –ê—Ä—Ö–∏–≤–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    return {
        'session_id': session_id,
        'video_path': video_path,
        'reports': report_paths,
        'statistics': final_stats,
        'processing_time': total_time
    }
```
```

### –ü–†–û–ú–ü–¢ 11: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö
```
–°–æ–∑–¥–∞–π core/data_aggregator.py –¥–ª—è –ü–û–õ–ù–û–ì–û –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö:

1. –ö–ª–∞—Å—Å DataAggregator —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:
```python
class DataAggregator:
    def aggregate_all_sources(self, video_emotions, audio_emotions, 
                            speech_transcript, face_tracking):
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        
    def create_unified_timeline(self):
        # –ï–¥–∏–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π
        
    def detect_anomalies(self):
        # –ü–æ–∏—Å–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –º–µ–∂–¥—É –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º–∏
```

2. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏:
```python
def synchronize_timestamps(self, sources):
    # –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
    min_time = min(s['start_time'] for s in sources)
    max_time = max(s['end_time'] for s in sources)
    
    # –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–µ—Ç–∫—É
    time_grid = np.arange(min_time, max_time, self.time_resolution)
    
    # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —ç—Ç—É —Å–µ—Ç–∫—É
    synchronized = {}
    for source_name, source_data in sources.items():
        synchronized[source_name] = self._interpolate_to_grid(
            source_data, time_grid
        )
```

3. –ü–æ–∏—Å–∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤:
```python
def detect_critical_moments(self):
    critical = []
    
    # –†–µ–∑–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —ç–º–æ—Ü–∏–π
    emotion_changes = self._detect_rapid_emotion_changes()
    
    # –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ
    mismatches = self._detect_modality_mismatches()
    
    # –î–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—É–∑—ã –≤ —Ä–µ—á–∏
    speech_pauses = self._detect_speech_anomalies()
    
    # –ú–∏–∫—Ä–æ–≤—ã—Ä–∞–∂–µ–Ω–∏—è
    micro_expressions = self._detect_micro_expressions()
    
    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
    critical = self._rank_by_importance(
        emotion_changes + mismatches + speech_pauses + micro_expressions
    )
```

4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:
```python
def calculate_correlations(self):
    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É —ç–º–æ—Ü–∏—è–º–∏ –ª–∏—Ü–∞ –∏ —Ä–µ—á–∏
    face_speech_corr = np.corrcoef(
        face_emotions_encoded, 
        speech_emotions_encoded
    )
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    patterns = self._find_temporal_patterns()
    
    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
    clusters = self._cluster_emotional_states()
```

5. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏:
```python
def calculate_comprehensive_statistics(self):
    stats = {
        'emotion_distribution': self._calculate_distribution(),
        'transition_matrix': self._create_transition_matrix(),
        'stability_index': self._calculate_stability(),
        'stress_level': self._estimate_stress_level(),
        'deception_probability': self._calculate_deception_score(),
        'cooperation_index': self._assess_cooperation()
    }
```

6. –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã:
```python
def create_annotated_timeline(self):
    timeline = []
    
    for timestamp in self.unified_timeline:
        timeline.append({
            'time': timestamp,
            'face_emotion': self.get_face_emotion_at(timestamp),
            'speech_emotion': self.get_speech_emotion_at(timestamp),
            'transcript': self.get_transcript_at(timestamp),
            'critical_level': self.get_criticality_at(timestamp),
            'annotations': self.get_annotations_at(timestamp)
        })
```

7. –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
   - DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
   - JSON –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
   - SQL –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
   - –ì—Ä–∞—Ñ–∏–∫ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
```

### –ü–†–û–ú–ü–¢ 12: –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
```
–°–æ–∑–¥–∞–π main.py - –ü–û–õ–ù–´–ô –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –±–µ–∑ —É–ø—Ä–æ—â–µ–Ω–∏–π:

1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è:
```python
st.set_page_config(
    page_title="–î–û–ü–†–û–° MVP 2.0",
    page_icon="üé•",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/your-repo',
        'Report a bug': "https://github.com/your-repo/issues",
        'About': "–î–û–ü–†–û–° MVP 2.0 - –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ –¥–æ–ø—Ä–æ—Å–æ–≤"
    }
)

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Å—Ç–∏–ª–∏
st.markdown('''
<style>
    .main {padding: 0rem 1rem;}
    .stProgress > div > div > div > div {background-color: #FF4444;}
    [data-testid="stSidebar"] {background-color: #f0f2f6;}
    .css-1d391kg {padding-top: 1rem;}
</style>
''', unsafe_allow_html=True)
```

2. –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:
```python
with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π
    st.subheader("ü§ñ –ú–æ–¥–µ–ª–∏")
    use_deepface = st.checkbox("DeepFace", value=True)
    use_fer = st.checkbox("FER", value=True)
    use_yolo_emotion = st.checkbox("YOLO —ç–º–æ—Ü–∏–∏", value=True)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    st.subheader("üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
    frame_skip = st.slider("–ü—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤", 1, 30, 15)
    confidence_threshold = st.slider("–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏", 0.1, 1.0, 0.5)
    
    # GPU –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    st.subheader("üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ")
    device_option = st.radio(
        "–í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞",
        ["–ê–≤—Ç–æ", "GPU", "CPU"],
        index=0
    )
    
    # –≠–∫—Å–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    st.subheader("üìÅ –≠–∫—Å–ø–æ—Ä—Ç")
    export_formats = st.multiselect(
        "–§–æ—Ä–º–∞—Ç—ã –æ—Ç—á–µ—Ç–æ–≤",
        ["CSV", "JSON", "HTML", "PDF", "Excel"],
        default=["CSV", "HTML"]
    )
```

3. –ì–ª–∞–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å —Å —Ç–∞–±–∞–º–∏:
```python
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìπ –ó–∞–≥—Ä—É–∑–∫–∞", 
    "üìä –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π", 
    "üéôÔ∏è –ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏",
    "üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", 
    "‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã",
    "üìà –û—Ç—á–µ—Ç—ã"
])

with tab1:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ")
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª",
            type=['mp4', 'avi', 'mov', 'mkv'],
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 2GB"
        )
        
    with col2:
        st.subheader("üé¨ –î–µ–º–æ –≤–∏–¥–µ–æ")
        if st.button("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ", type="primary"):
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ–º–æ –≤–∏–¥–µ–æ
```

4. –ü—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º:
```python
if st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨ –ê–ù–ê–õ–ò–ó", type="primary"):
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    progress_bar = st.progress(0)
    status_text = st.empty()
    log_container = st.container()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = MasterPipeline(config)
    
    def update_progress(progress, stage_name, details=""):
        progress_bar.progress(progress)
        status_text.text(f"–≠—Ç–∞–ø: {stage_name}")
        if details:
            with log_container:
                st.info(f"üìç {details}")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å callback
    results = pipeline.process_video(
        video_path,
        progress_callback=update_progress
    )
```

5. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
```python
with tab2:  # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
    st.subheader("üé≠ –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —ç–º–æ—Ü–∏–π")
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
    fig = create_emotion_timeline(results['emotions'])
    st.plotly_chart(fig, use_container_width=True)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è", results['dominant_emotion'])
    with col2:
        st.metric("–ò–∑–º–µ–Ω–µ–Ω–∏–π —ç–º–æ—Ü–∏–π", results['emotion_changes'])
    with col3:
        st.metric("–£—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞", f"{results['stress_level']:.1%}")
    with col4:
        st.metric("–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", f"{results['stability']:.1%}")
    
    # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
    st.subheader("üó∫Ô∏è –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —ç–º–æ—Ü–∏–π")
    heatmap_fig = create_emotion_heatmap(results['emotion_matrix'])
    st.plotly_chart(heatmap_fig, use_container_width=True)
```

6. –ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏ —Å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º:
```python
with tab3:  # –ê–Ω–∞–ª–∏–∑ —Ä–µ—á–∏
    st.subheader("üéôÔ∏è –≠–º–æ—Ü–∏–∏ –≤ —Ä–µ—á–∏")
    
    # –ì—Ä–∞—Ñ–∏–∫ —ç–º–æ—Ü–∏–π –≤ —Ä–µ—á–∏
    speech_fig = create_speech_emotion_plot(results['speech_emotions'])
    st.plotly_chart(speech_fig, use_container_width=True)
    
    # –ê—É–¥–∏–æ –ø–ª–µ–µ—Ä —Å –º–µ—Ç–∫–∞–º–∏
    st.audio(results['audio_path'])
    
    # –¢–∞–±–ª–∏—Ü–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    st.dataframe(
        results['speech_segments'],
        use_container_width=True,
        height=300
    )
```

7. –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π:
```python
with tab4:  # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
    st.subheader("üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –¥–æ–ø—Ä–æ—Å–∞")
    
    # –í—ã–±–æ—Ä –≤–µ—Ä—Å–∏–∏
    version = st.radio(
        "–í–µ—Ä—Å–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞",
        ["–û—Ä–∏–≥–∏–Ω–∞–ª", "–£–ª—É—á—à–µ–Ω–Ω–∞—è", "–° —Ä–∞–∑–º–µ—Ç–∫–æ–π"]
    )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤
    if version == "–° —Ä–∞–∑–º–µ—Ç–∫–æ–π":
        for segment in results['transcript_segments']:
            if segment['critical']:
                st.markdown(f"""
                <div style="background-color: #ffcccc; padding: 10px; 
                           border-left: 3px solid red;">
                    <b>{segment['speaker']}:</b> {segment['text']}
                    <br><small>‚è±Ô∏è {segment['time']}</small>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"**{segment['speaker']}:** {segment['text']}")
```

8. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã:
```python
with tab5:  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã
    st.subheader("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã")
    
    for idx, moment in enumerate(results['critical_moments']):
        with st.expander(f"üî¥ –ú–æ–º–µ–Ω—Ç {idx+1}: {moment['time']}"):
            st.write(f"**–¢–∏–ø:** {moment['type']}")
            st.write(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {moment['description']}")
            st.write(f"**–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏:** {moment['severity']}/10")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –∫–∞–¥—Ä
            if moment['frame']:
                st.image(moment['frame'], caption=f"–ö–∞–¥—Ä –≤ {moment['time']}")
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç
            st.write("**–ö–æ–Ω—Ç–µ–∫—Å—Ç:**")
            st.write(f"- –≠–º–æ—Ü–∏—è –ª–∏—Ü–∞: {moment['face_emotion']}")
            st.write(f"- –≠–º–æ—Ü–∏—è —Ä–µ—á–∏: {moment['speech_emotion']}")
            st.write(f"- –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: {moment['transcript']}")
```

9. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤:
```python
with tab6:  # –û—Ç—á–µ—Ç—ã
    st.subheader("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤")
    
    # GPT –∏–Ω—Å–∞–π—Ç—ã
    with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Å–∞–π—Ç–æ–≤..."):
        insights = results['gpt_insights']
        
    st.markdown("### üß† –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
    st.write(insights)
    
    # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    st.markdown("### üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç—ã")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.download_button(
            label="üìÑ CSV –¥–∞–Ω–Ω—ã–µ",
            data=results['csv_data'],
            file_name="analysis_data.csv",
            mime="text/csv"
        )
    
    with col2:
        st.download_button(
            label="üìä HTML –æ—Ç—á–µ—Ç",
            data=results['html_report'],
            file_name="full_report.html",
            mime="text/html"
        )
    
    with col3:
        st.download_button(
            label="üìë PDF –æ—Ç—á–µ—Ç",
            data=results['pdf_report'],
            file_name="interrogation_analysis.pdf",
            mime="application/pdf"
        )
```

10. –§—É—Ç–µ—Ä —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π:
```python
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**–í–µ—Ä—Å–∏—è:** 2.0.0")
    
with col2:
    if 'processing_time' in results:
        st.markdown(f"**–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {results['processing_time']:.1f} —Å–µ–∫")
        
with col3:
    st.markdown("**¬© 2025 –î–û–ü–†–û–° MVP**")
```
```

### –ü–†–û–ú–ü–¢ 13: –°–∏—Å—Ç–µ–º–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
```
–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ tests/:

1. test_compatibility.py - –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
   - –¢–µ—Å—Ç –≤—Å–µ—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU/CUDA
   - –ù–∞–ª–∏—á–∏–µ FFmpeg
   - API –∫–ª—é—á–∏
   - –ú–æ–¥–µ–ª–∏ YOLO
   - –í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫

2. test_pipeline.py - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã:
   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–º–æ –≤–∏–¥–µ–æ
   - –í—Å–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
   - Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã
   - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫

3. test_models.py - —Ç–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π:
   - YOLO –¥–µ—Ç–µ–∫—Ü–∏—è
   - DeepFace –∞–Ω–∞–ª–∏–∑
   - FER —Ä–∞–±–æ—Ç–∞
   - Speech –∞–Ω–∞–ª–∏–∑

4. fixtures/ - —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:
   - –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ (10 —Å–µ–∫)
   - –ê—É–¥–∏–æ —Å—ç–º–ø–ª
   - –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ó–∞–ø—É—Å–∫: pytest tests/ -v --cov=core --cov=models
```

### –ü–†–û–ú–ü–¢ 14: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ README
```
–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é:

1. README.md —Å:
   - –û–ø–∏—Å–∞–Ω–∏–µ–º –ø—Ä–æ–µ–∫—Ç–∞
   - –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ —Å–∏—Å—Ç–µ–º–µ
   - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ
   - –ü—Ä–∏–º–µ—Ä–∞–º–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
   - Troubleshooting
   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã

2. docs/API.md:
   - –û–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
   - –ú–µ—Ç–æ–¥—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
   - –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞

3. docs/MODELS.md:
   - –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏
   - –ò—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
   - –ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ

4. docs/DEPLOYMENT.md:
   - –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
   - Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
   - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```

## üöÄ –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨ –†–ï–ê–õ–ò–ó–ê–¶–ò–ò

### –î–µ–Ω—å 1: –§—É–Ω–¥–∞–º–µ–Ω—Ç
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 1 - —Å–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É
2. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 2 - GPU –º–µ–Ω–µ–¥–∂–µ—Ä
3. –ö–æ–º–º–∏—Ç: "Initial setup with GPU management"

### –î–µ–Ω—å 2: YOLO –∏ –¥–µ—Ç–µ–∫—Ü–∏—è
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 3 - YOLO –º–µ–Ω–µ–¥–∂–µ—Ä
2. –¢–µ—Å—Ç–∏—Ä—É–π –Ω–∞ –¥–µ–º–æ –≤–∏–¥–µ–æ
3. –ö–æ–º–º–∏—Ç: "YOLO11 integration complete"

### –î–µ–Ω—å 3: –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 4 - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
2. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 5 - –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
3. –ö–æ–º–º–∏—Ç: "Emotion analysis with fallbacks"

### –î–µ–Ω—å 4: –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 6 - –∞–Ω–∞–ª–∏–∑ —Ä–µ—á–∏
2. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 7 - –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∞—É–¥–∏–æ
3. –ö–æ–º–º–∏—Ç: "Audio processing complete"

### –î–µ–Ω—å 5: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 8 - OpenAI –∫–ª–∏–µ–Ω—Ç
2. –¢–µ—Å—Ç–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
3. –ö–æ–º–º–∏—Ç: "OpenAI integration"

### –î–µ–Ω—å 6: –û—Ç—á–µ—Ç—ã –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 9 - –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤
2. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 11 - –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä
3. –ö–æ–º–º–∏—Ç: "Report generation system"

### –î–µ–Ω—å 7: –ü–∞–π–ø–ª–∞–π–Ω
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 10 - –≥–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
3. –ö–æ–º–º–∏—Ç: "Master pipeline complete"

### –î–µ–Ω—å 8: –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 12 - Streamlit UI
2. –¢–µ—Å—Ç–∏—Ä—É–π –≤–µ—Å—å —Ñ–ª–æ—É
3. –ö–æ–º–º–∏—Ç: "Full UI implementation"

### –î–µ–Ω—å 9: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 13 - —Ç–µ—Å—Ç—ã
2. –ò—Å–ø—Ä–∞–≤—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
3. –ö–æ–º–º–∏—Ç: "Testing and fixes"

### –î–µ–Ω—å 10: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
1. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–ú–ü–¢ 14 - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
3. –ö–æ–º–º–∏—Ç: "v2.0.0 release"

## ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û

1. **–ù–ï –£–ü–†–û–©–ê–ô** - —Ä–µ–∞–ª–∏–∑—É–π –í–°–ï —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –ø—Ä–æ–º–ø—Ç–æ–≤
2. **–¢–ï–°–¢–ò–†–£–ô** –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
3. **–ö–û–ú–ú–ò–¢–¨** —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–π –∫–æ–¥
4. **–õ–û–ì–ò–†–£–ô** –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
5. **FALLBACK** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
6. **–ö–≠–®–ò–†–£–ô** –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
7. **–î–û–ö–£–ú–ï–ù–¢–ò–†–£–ô** –∫–∞–∂–¥—ã–π –º–µ—Ç–æ–¥

## üìã –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ú–ü–¢–´

### –ü–†–û–ú–ü–¢ 15: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –¥–æ–ø—Ä–æ—Å–æ–≤
```
–°–æ–∑–¥–∞–π core/critical_analyzer.py –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –¥–æ–ø—Ä–æ—Å–∞:

1. –ö–ª–∞—Å—Å InterrogationCriticalAnalyzer:
   - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤
   - –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±–º–∞–Ω–∞
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è
   - –ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π

2. –ú–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±–º–∞–Ω–∞:
```python
def detect_deception_indicators(self):
    indicators = {
        'micro_expressions': self._detect_micro_expressions(),
        'voice_stress': self._analyze_voice_stress(),
        'eye_movement': self._track_eye_patterns(),
        'body_language': self._analyze_body_language(),
        'verbal_cues': self._detect_verbal_indicators(),
        'response_latency': self._measure_response_time(),
        'emotional_leakage': self._detect_emotional_leakage()
    }
    
    # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ–±–º–∞–Ω–∞
    deception_score = self._calculate_weighted_score(indicators)
```

3. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π:
```python
def find_contradictions(self, transcript_segments):
    contradictions = []
    
    # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
    statements = self._extract_factual_statements(transcript_segments)
    
    # –ü–æ–∏—Å–∫ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
    for i, stmt1 in enumerate(statements):
        for stmt2 in statements[i+1:]:
            if self._are_contradictory(stmt1, stmt2):
                contradictions.append({
                    'statement1': stmt1,
                    'statement2': stmt2,
                    'times': [stmt1['time'], stmt2['time']],
                    'type': self._classify_contradiction(stmt1, stmt2),
                    'significance': self._assess_significance(stmt1, stmt2)
                })
```

4. –ü–∞—Ç—Ç–µ—Ä–Ω—ã —É–∫–ª–æ–Ω–µ–Ω–∏—è:
```python
def detect_evasion_patterns(self):
    patterns = {
        'question_avoidance': [],  # –ù–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –ø—Ä—è–º–æ–π –≤–æ–ø—Ä–æ—Å
        'topic_shifting': [],       # –°–º–µ–Ω–∞ —Ç–µ–º—ã
        'vague_responses': [],      # –†–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã
        'excessive_details': [],    # –ò–∑–ª–∏—à–Ω–∏–µ –¥–µ—Ç–∞–ª–∏ (–ø—Ä–∏–∑–Ω–∞–∫ –ª–∂–∏)
        'memory_issues': [],        # "–ù–µ –ø–æ–º–Ω—é" –≤ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–∞—Ö
        'deflection': []           # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–Ω—ã
    }
```

5. –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–µ—Å—Å–∞ –∏ –¥–∞–≤–ª–µ–Ω–∏—è:
```python
def analyze_stress_dynamics(self):
    # –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞ (–ø–µ—Ä–≤—ã–µ –º–∏–Ω—É—Ç—ã)
    baseline = self._establish_baseline()
    
    # –î–∏–Ω–∞–º–∏–∫–∞ —Å—Ç—Ä–µ—Å—Å–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    stress_timeline = []
    for segment in self.timeline:
        stress_level = self._calculate_stress(segment, baseline)
        stress_timeline.append({
            'time': segment['time'],
            'stress': stress_level,
            'factors': self._identify_stress_factors(segment),
            'recovery_time': self._measure_recovery(segment)
        })
```

6. –ö–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ä–µ–∞–∫—Ü–∏–∏:
```python
def map_questions_to_reactions(self, transcript, emotions):
    qa_map = []
    
    questions = self._extract_questions(transcript)
    for question in questions:
        reaction = {
            'question': question['text'],
            'question_time': question['time'],
            'emotion_before': self._get_emotion_at(question['time'] - 2),
            'emotion_during': self._get_emotion_at(question['time']),
            'emotion_after': self._get_emotion_at(question['time'] + 5),
            'response_time': self._measure_response_latency(question),
            'stress_spike': self._detect_stress_spike(question['time']),
            'significance': self._assess_question_impact(question)
        }
        qa_map.append(reaction)
```

7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:
```python
def generate_investigative_recommendations(self):
    recommendations = {
        'high_priority_topics': self._identify_sensitive_topics(),
        'followup_questions': self._suggest_followup_questions(),
        'behavioral_flags': self._summarize_behavioral_indicators(),
        'credibility_assessment': self._assess_overall_credibility(),
        'suggested_verification': self._suggest_fact_checking(),
        'psychological_profile': self._create_psychological_profile()
    }
```
```

### –ü–†–û–ú–ü–¢ 16: –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
```
–°–æ–∑–¥–∞–π utils/session_manager.py –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:

1. –ö–ª–∞—Å—Å SessionManager –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è:
   - –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–µ—Å—Å–∏–π
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
   - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Å–±–æ–µ–≤
   - –ò—Å—Ç–æ—Ä–∏—è –æ–±—Ä–∞–±–æ—Ç–æ–∫

2. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏—è–º–∏:
```python
class SessionManager:
    def create_session(self, video_path, user_id=None):
        session_id = self._generate_session_id(video_path)
        session_data = {
            'id': session_id,
            'video_path': video_path,
            'video_hash': self._calculate_file_hash(video_path),
            'user_id': user_id,
            'created_at': datetime.now(),
            'status': 'initialized',
            'stages_completed': [],
            'stages_pending': [],
            'results': {},
            'errors': [],
            'config': self._capture_config()
        }
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å–µ—Å—Å–∏–∏
        self._create_session_directories(session_id)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        self._save_session_metadata(session_data)
        
        return session_id

3. Checkpoint —Å–∏—Å—Ç–µ–º–∞:
```python
def save_checkpoint(self, session_id, stage_name, data):
    checkpoint_path = f"storage/sessions/{session_id}/checkpoints/{stage_name}.pkl"
    
    checkpoint = {
        'stage': stage_name,
        'timestamp': datetime.now(),
        'data': data,
        'data_hash': hashlib.md5(pickle.dumps(data)).hexdigest(),
        'stage_version': self._get_stage_version(stage_name)
    }
    
    with open(checkpoint_path, 'wb') as f:
        pickle.dump(checkpoint, f)
    
    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
    self._update_session_status(session_id, stage_name, 'completed')

4. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏:
```python
def restore_session(self, session_id):
    metadata = self._load_session_metadata(session_id)
    
    if metadata['status'] == 'completed':
        return self._load_completed_session(session_id)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
    last_checkpoint = self._find_last_valid_checkpoint(session_id)
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    restored_data = {}
    for stage in metadata['stages_completed']:
        checkpoint = self._load_checkpoint(session_id, stage)
        if self._validate_checkpoint(checkpoint):
            restored_data[stage] = checkpoint['data']
    
    return {
        'session_id': session_id,
        'resume_from': last_checkpoint,
        'completed_stages': metadata['stages_completed'],
        'pending_stages': metadata['stages_pending'],
        'data': restored_data
    }

5. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–µ–π:
```python
def get_session_history(self, user_id=None, days=30):
    sessions = []
    
    for session_dir in os.listdir('storage/sessions'):
        metadata = self._load_session_metadata(session_dir)
        
        if user_id and metadata.get('user_id') != user_id:
            continue
            
        if (datetime.now() - metadata['created_at']).days > days:
            continue
            
        sessions.append({
            'id': metadata['id'],
            'video_name': os.path.basename(metadata['video_path']),
            'created': metadata['created_at'],
            'status': metadata['status'],
            'progress': len(metadata['stages_completed']) / len(self.all_stages),
            'has_results': 'results' in metadata and bool(metadata['results'])
        })
    
    return sorted(sessions, key=lambda x: x['created'], reverse=True)

6. –û—á–∏—Å—Ç–∫–∞ –∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏—è:
```python
def cleanup_old_sessions(self, max_age_days=7, archive=True):
    for session_dir in os.listdir('storage/sessions'):
        metadata = self._load_session_metadata(session_dir)
        age = (datetime.now() - metadata['created_at']).days
        
        if age > max_age_days:
            if archive:
                self._archive_session(session_dir)
            self._delete_session(session_dir)
```
```

### –ü–†–û–ú–ü–¢ 17: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö
```
–°–æ–∑–¥–∞–π utils/validators.py —Å –ü–û–õ–ù–û–ô –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö:

1. –ö–ª–∞—Å—Å ComprehensiveValidator:
```python
class ComprehensiveValidator:
    def __init__(self, config):
        self.config = config
        self.validation_rules = self._load_validation_rules()
        
    def validate_all(self):
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º"""
        validations = [
            ('system', self.validate_system_requirements()),
            ('dependencies', self.validate_dependencies()),
            ('models', self.validate_models()),
            ('api_keys', self.validate_api_keys()),
            ('storage', self.validate_storage()),
            ('gpu', self.validate_gpu_availability())
        ]
        
        report = ValidationReport()
        for name, result in validations:
            report.add_validation(name, result)
        
        return report

2. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞:
```python
def validate_video_file(self, video_path):
    checks = {
        'exists': os.path.exists(video_path),
        'readable': os.access(video_path, os.R_OK),
        'format': self._check_video_format(video_path),
        'codec': self._check_video_codec(video_path),
        'duration': self._check_duration(video_path),
        'resolution': self._check_resolution(video_path),
        'framerate': self._check_framerate(video_path),
        'size': self._check_file_size(video_path),
        'corruption': self._check_corruption(video_path)
    }
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ
    if all(checks.values()):
        video_info = self._extract_video_metadata(video_path)
        return ValidationResult(True, video_info)
    else:
        failures = [k for k, v in checks.items() if not v]
        return ValidationResult(False, {'failed_checks': failures})

3. –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ML:
```python
def validate_models(self):
    model_checks = {}
    
    # YOLO –º–æ–¥–µ–ª–∏
    for model_name in ['yolo11n.pt', 'yolo11n-face.pt']:
        model_path = f"assets/models/{model_name}"
        model_checks[model_name] = {
            'exists': os.path.exists(model_path),
            'size_valid': os.path.getsize(model_path) > 1000000,  # > 1MB
            'loadable': self._try_load_yolo(model_path),
            'version': self._check_yolo_version(model_path)
        }
    
    # DeepFace
    model_checks['deepface'] = {
        'importable': self._can_import('deepface'),
        'models_downloaded': self._check_deepface_models(),
        'backend_available': self._check_deepface_backend()
    }
    
    # FER
    model_checks['fer'] = {
        'importable': self._can_import('fer'),
        'mtcnn_available': self._check_mtcnn()
    }
    
    return model_checks

4. –í–∞–ª–∏–¥–∞—Ü–∏—è API:
```python
def validate_api_keys(self):
    api_checks = {}
    
    # OpenAI
    openai_key = os.getenv('OPENAI_API_KEY')
    if openai_key:
        api_checks['openai'] = {
            'key_present': True,
            'key_format': self._validate_openai_key_format(openai_key),
            'api_accessible': self._test_openai_api(openai_key),
            'models_available': self._check_openai_models(openai_key)
        }
    else:
        api_checks['openai'] = {'key_present': False}
    
    return api_checks

5. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
```python
def validate_analysis_results(self, results):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    
    validations = {
        'structure': self._validate_result_structure(results),
        'timestamps': self._validate_timestamps(results),
        'emotions': self._validate_emotion_data(results),
        'transcript': self._validate_transcript(results),
        'consistency': self._check_data_consistency(results),
        'completeness': self._check_completeness(results)
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
    anomalies = self._detect_result_anomalies(results)
    if anomalies:
        validations['anomalies'] = anomalies
    
    return validations

6. –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π:
```python
def validate_system_requirements(self):
    requirements = {
        'python_version': sys.version_info >= (3, 8),
        'ram_available': psutil.virtual_memory().total >= 8 * 1024**3,  # 8GB
        'disk_space': shutil.disk_usage('/').free >= 10 * 1024**3,  # 10GB
        'ffmpeg_installed': shutil.which('ffmpeg') is not None,
        'internet_connection': self._check_internet(),
        'write_permissions': self._check_write_permissions()
    }
    
    return requirements
```
```

### –ü–†–û–ú–ü–¢ 18: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
```
–°–æ–∑–¥–∞–π utils/logger.py –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:

1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞:
```python
import logging
import logging.handlers
from datetime import datetime
import json
import traceback

class CustomLogger:
    def __init__(self, name='DOPROS_MVP', config=None):
        self.logger = logging.getLogger(name)
        self.config = config or self._load_config()
        self._setup_handlers()
        self._setup_formatters()
        
    def _setup_handlers(self):
        # –§–∞–π–ª–æ–≤—ã–π handler —Å —Ä–æ—Ç–∞—Ü–∏–µ–π
        file_handler = logging.handlers.RotatingFileHandler(
            'logs/dopros.log',
            maxBytes=100*1024*1024,  # 100MB
            backupCount=5,
            encoding='utf-8'
        )
        
        # Console handler —Å —Ü–≤–µ—Ç–∞–º–∏
        console_handler = ColoredConsoleHandler()
        
        # JSON handler –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤
        json_handler = JSONLogHandler('logs/dopros.json')
        
        # Error handler –æ—Ç–¥–µ–ª—å–Ω–æ
        error_handler = logging.handlers.RotatingFileHandler(
            'logs/errors.log',
            maxBytes=50*1024*1024,
            backupCount=3
        )
        error_handler.setLevel(logging.ERROR)

2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ª–æ–≥–≥–µ—Ä:
```python
class ContextLogger:
    def __init__(self, logger, context):
        self.logger = logger
        self.context = context
        
    def log(self, level, message, **kwargs):
        extra = {'context': self.context, **kwargs}
        self.logger.log(level, message, extra=extra)
    
    def log_stage(self, stage_name, status, duration=None, **details):
        self.log(
            logging.INFO,
            f"Stage: {stage_name} - Status: {status}",
            stage=stage_name,
            status=status,
            duration=duration,
            details=details
        )

3. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
```python
class PerformanceMonitor:
    def __init__(self, logger):
        self.logger = logger
        self.metrics = {}
        
    @contextmanager
    def measure(self, operation_name):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss
        
        try:
            yield
        finally:
            duration = time.time() - start_time
            memory_delta = psutil.Process().memory_info().rss - start_memory
            
            self.metrics[operation_name] = {
                'duration': duration,
                'memory_delta': memory_delta,
                'timestamp': datetime.now()
            }
            
            self.logger.info(
                f"Performance: {operation_name}",
                extra={
                    'operation': operation_name,
                    'duration_sec': duration,
                    'memory_mb': memory_delta / 1024 / 1024
                }
            )

4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:
```python
def log_exception(self, exception, context=None, critical=False):
    exc_info = {
        'type': type(exception).__name__,
        'message': str(exception),
        'traceback': traceback.format_exc(),
        'context': context or {},
        'timestamp': datetime.now().isoformat()
    }
    
    if critical:
        self.logger.critical(
            f"CRITICAL ERROR: {exception}",
            extra=exc_info,
            exc_info=True
        )
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        self._send_critical_alert(exc_info)
    else:
        self.logger.error(
            f"Error: {exception}",
            extra=exc_info,
            exc_info=True
        )

5. –ê—É–¥–∏—Ç –¥–µ–π—Å—Ç–≤–∏–π:
```python
class AuditLogger:
    def log_action(self, action, user=None, details=None):
        audit_entry = {
            'action': action,
            'user': user or 'system',
            'timestamp': datetime.now().isoformat(),
            'details': details or {},
            'session_id': self.get_current_session_id()
        }
        
        # –ó–∞–ø–∏—Å—å –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –∞—É–¥–∏—Ç–∞
        with open('logs/audit.jsonl', 'a', encoding='utf-8') as f:
            f.write(json.dumps(audit_entry, ensure_ascii=False) + '\n')
```
```

### –ü–†–û–ú–ü–¢ 19: Docker –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
```
–°–æ–∑–¥–∞–π —Ñ–∞–π–ª—ã –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è:

1. Dockerfile —Å multi-stage build:
```dockerfile
# Stage 1: Builder
FROM python:3.10-slim as builder

WORKDIR /app

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libglib2.0-0 \
    libgomp1 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ requirements –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Stage 2: Runtime
FROM python:3.10-slim

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏–∑ builder
COPY --from=builder /usr/lib /usr/lib
COPY --from=builder /usr/bin/ffmpeg /usr/bin/ffmpeg

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Python –ø–∞–∫–µ—Ç–æ–≤
COPY --from=builder /root/.local /root/.local

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY . .

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
RUN mkdir -p storage/videos storage/audio storage/frames \
    storage/results storage/reports storage/cache logs

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
ENV PYTHONPATH=/app
ENV PATH=/root/.local/bin:$PATH
ENV STREAMLIT_SERVER_PORT=8501
ENV STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8501/_stcore/health || exit 1

# –ü–æ—Ä—Ç
EXPOSE 8501

# –ó–∞–ø—É—Å–∫
CMD ["streamlit", "run", "main.py", "--server.maxUploadSize=2000"]
```

2. docker-compose.yml –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å—Ç–µ–∫–∞:
```yaml
version: '3.8'

services:
  dopros-app:
    build: .
    container_name: dopros-mvp
    ports:
      - "8501:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    volumes:
      - ./storage:/app/storage
      - ./logs:/app/logs
      - ./assets/models:/app/assets/models
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    container_name: dopros-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - dopros-app
    restart: unless-stopped

  redis:
    image: redis:alpine
    container_name: dopros-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped

volumes:
  redis-data:
```

3. Kubernetes deployment:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dopros-mvp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: dopros
  template:
    metadata:
      labels:
        app: dopros
    spec:
      containers:
      - name: dopros
        image: dopros-mvp:2.0.0
        ports:
        - containerPort: 8501
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: 1
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: dopros-secrets
              key: openai-key
        volumeMounts:
        - name: storage
          mountPath: /app/storage
        - name: models
          mountPath: /app/assets/models
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: dopros-storage
      - name: models
        persistentVolumeClaim:
          claimName: dopros-models
```

4. CI/CD pipeline (.gitlab-ci.yml):
```yaml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA

test:
  stage: test
  image: python:3.10
  script:
    - pip install -r requirements.txt
    - pytest tests/ -v --cov=core --cov=models
    - python tests/test_compatibility.py
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker build -t $DOCKER_IMAGE .
    - docker push $DOCKER_IMAGE

deploy:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl set image deployment/dopros-mvp dopros=$DOCKER_IMAGE
    - kubectl rollout status deployment/dopros-mvp
  only:
    - main
```
```

### –ü–†–û–ú–ü–¢ 20: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```
–°–æ–∑–¥–∞–π utils/optimizer.py –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

1. –ö–ª–∞—Å—Å PerformanceOptimizer:
```python
class PerformanceOptimizer:
    def __init__(self, config):
        self.config = config
        self.profiler = cProfile.Profile()
        self.memory_tracker = tracemalloc
        
    def optimize_video_processing(self, video_path):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        optimizations = {
            'frame_skip': self._calculate_optimal_frame_skip(video_path),
            'batch_size': self._calculate_optimal_batch_size(),
            'resolution': self._calculate_optimal_resolution(video_path),
            'codec': self._select_optimal_codec(),
            'parallel_workers': self._calculate_workers_count()
        }
        
        return optimizations
    
    def optimize_memory_usage(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤
        resource.setrlimit(
            resource.RLIMIT_AS,
            (self.config['performance']['memory_limit_gb'] * 1024**3, -1)
        )
    
    def profile_operation(self, func, *args, **kwargs):
        """–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        self.profiler.enable()
        result = func(*args, **kwargs)
        self.profiler.disable()
        
        stats = pstats.Stats(self.profiler)
        stats.sort_stats('cumulative')
        
        return result, stats
    
    def optimize_model_inference(self, model):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏"""
        if hasattr(model, 'fuse'):
            model.fuse()  # Fusion –¥–ª—è YOLO
        
        if hasattr(model, 'half') and torch.cuda.is_available():
            model.half()  # FP16 –¥–ª—è GPU
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        if hasattr(torch, 'compile'):
            model = torch.compile(model)
        
        return model

2. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
```python
class SmartCache:
    def __init__(self, max_size_gb=5, ttl_hours=24):
        self.cache_dir = "storage/cache"
        self.max_size = max_size_gb * 1024**3
        self.ttl = ttl_hours * 3600
        self.index = self._load_index()
    
    def get_or_compute(self, key, compute_func, *args, **kwargs):
        cache_path = self._get_cache_path(key)
        
        if self._is_cached(key) and not self._is_expired(key):
            return self._load_from_cache(cache_path)
        
        result = compute_func(*args, **kwargs)
        self._save_to_cache(key, result)
        
        return result
    
    def _manage_size(self):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–º –∫—ç—à–∞"""
        total_size = self._calculate_cache_size()
        
        if total_size > self.max_size:
            # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            entries = sorted(
                self.index.items(),
                key=lambda x: x[1]['accessed'],
                reverse=True
            )
            
            while total_size > self.max_size * 0.8:  # 80% threshold
                oldest_key = entries.pop()[0]
                self._remove_from_cache(oldest_key)
                total_size = self._calculate_cache_size()

3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:
```python
class ParallelProcessor:
    def __init__(self, max_workers=None):
        self.max_workers = max_workers or cpu_count()
        
    def process_frames_parallel(self, frames, process_func):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤"""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for i, frame in enumerate(frames):
                future = executor.submit(process_func, frame, index=i)
                futures.append(future)
            
            results = []
            for future in tqdm(as_completed(futures), total=len(futures)):
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                except Exception as e:
                    self.logger.error(f"Frame processing error: {e}")
                    results.append(None)
        
        return results

4. –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:
```python
def create_batches(data, batch_size=32):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞—Ç—á–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    for i in range(0, len(data), batch_size):
        yield data[i:i + batch_size]

def process_in_batches(self, data, model, batch_size=32):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏"""
    results = []
    
    for batch in create_batches(data, batch_size):
        batch_tensor = torch.stack([self.preprocess(item) for item in batch])
        
        with torch.no_grad():
            if self.device != 'cpu':
                batch_tensor = batch_tensor.to(self.device)
            
            batch_results = model(batch_tensor)
            results.extend(batch_results.cpu().numpy())
    
    return results
```
```

### –ü–†–û–ú–ü–¢ 21: –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫
```
–°–æ–∑–¥–∞–π —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å–±–æ—Ä–∫–∏ –∏ –∑–∞–ø—É—Å–∫–∞:

1. setup.py –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏:
```python
#!/usr/bin/env python
import os
import sys
import subprocess
from pathlib import Path

def setup_project():
    """–ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    print("üöÄ –î–û–ü–†–û–° MVP 2.0 - –£—Å—Ç–∞–Ω–æ–≤–∫–∞")
    print("=" * 50)
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –≤–µ—Ä—Å–∏–∏
    if sys.version_info < (3, 8):
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.8+")
        sys.exit(1)
    
    # 2. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    print("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    subprocess.run([sys.executable, "-m", "venv", "venv"])
    
    # 3. –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–æ–≤
    pip_path = "venv/Scripts/pip" if os.name == 'nt' else "venv/bin/pip"
    
    print("üìö –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
    subprocess.run([pip_path, "install", "--upgrade", "pip"])
    subprocess.run([pip_path, "install", "-r", "requirements.txt"])
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫...")
    dirs = [
        "storage/videos", "storage/audio", "storage/frames",
        "storage/faces", "storage/faces_yolo11", "storage/results",
        "storage/reports", "storage/cache", "storage/sessions",
        "logs", "assets/models"
    ]
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    # 5. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    download_models()
    
    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ FFmpeg
    if not check_ffmpeg():
        print("‚ö†Ô∏è  FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: https://ffmpeg.org/download.html")
    
    # 7. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not os.path.exists('.env'):
        print("üîë –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞...")
        with open('.env', 'w') as f:
            f.write("OPENAI_API_KEY=your_key_here\n")
            f.write("LOG_LEVEL=INFO\n")
        print("‚ö†Ô∏è  –î–æ–±–∞–≤—å—Ç–µ –≤–∞—à OpenAI API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª")
    
    # 8. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏...")
    test_result = subprocess.run(
        [pip_path.replace('pip', 'python'), "tests/test_compatibility.py"],
        capture_output=True
    )
    
    if test_result.returncode == 0:
        print("‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("\nüìå –î–ª—è –∑–∞–ø—É—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   python run.py")
        print("   –∏–ª–∏")
        print("   streamlit run main.py")
    else:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.")

def download_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    import urllib.request
    
    models = {
        "yolo11n.pt": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolo11n.pt",
        # –î–æ–±–∞–≤–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
    }
    
    for model_name, url in models.items():
        model_path = f"assets/models/{model_name}"
        if not os.path.exists(model_path):
            print(f"  –ó–∞–≥—Ä—É–∑–∫–∞ {model_name}...")
            urllib.request.urlretrieve(url, model_path)

def check_ffmpeg():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è FFmpeg"""
    try:
        subprocess.run(["ffmpeg", "-version"], capture_output=True)
        return True
    except FileNotFoundError:
        return False

if __name__ == "__main__":
    setup_project()
```

2. run.py –¥–ª—è –∑–∞–ø—É—Å–∫–∞:
```python
#!/usr/bin/env python
import os
import sys
import argparse
import subprocess
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description='–î–û–ü–†–û–° MVP 2.0')
    parser.add_argument('--mode', choices=['web', 'cli', 'api'], 
                       default='web', help='–†–µ–∂–∏–º –∑–∞–ø—É—Å–∫–∞')
    parser.add_argument('--video', type=str, help='–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ –¥–ª—è CLI —Ä–µ–∂–∏–º–∞')
    parser.add_argument('--port', type=int, default=8501, help='–ü–æ—Ä—Ç –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞')
    parser.add_argument('--debug', action='store_true', help='–†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏')
    parser.add_argument('--gpu', action='store_true', help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU')
    parser.add_argument('--test', action='store_true', help='–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã')
    
    args = parser.parse_args()
    
    if args.test:
        run_tests()
        return
    
    if args.mode == 'web':
        run_web(args.port, args.debug)
    elif args.mode == 'cli':
        if not args.video:
            print("‚ùå –£–∫–∞–∂–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª: --video path/to/video.mp4")
            sys.exit(1)
        run_cli(args.video, args.gpu)
    elif args.mode == 'api':
        run_api(args.port)

def run_web(port, debug):
    """–ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    print(f"üåê –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    
    env = os.environ.copy()
    if debug:
        env['LOG_LEVEL'] = 'DEBUG'
        env['STREAMLIT_THEME_BASE'] = 'light'
    
    cmd = [
        "streamlit", "run", "main.py",
        f"--server.port={port}",
        "--server.maxUploadSize=2000"
    ]
    
    if debug:
        cmd.append("--logger.level=debug")
    
    subprocess.run(cmd, env=env)

def run_cli(video_path, use_gpu):
    """–ó–∞–ø—É—Å–∫ –≤ CLI —Ä–µ–∂–∏–º–µ"""
    print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: {video_path}")
    
    from core.pipeline import MasterPipeline
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = load_config()
    if not use_gpu:
        config['processing']['models']['yolo']['force_cpu'] = True
    
    # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
    pipeline = MasterPipeline(config)
    
    def progress_callback(progress, stage):
        bar_length = 50
        filled = int(bar_length * progress)
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        print(f'\r[{bar}] {progress:.1%} - {stage}', end='')
    
    results = pipeline.process_video(video_path, progress_callback=progress_callback)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results['reports']['main']}")

def run_api(port):
    """–ó–∞–ø—É—Å–∫ API —Å–µ—Ä–≤–µ—Ä–∞"""
    print(f"üîå –ó–∞–ø—É—Å–∫ API –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å FastAPI —Å–µ—Ä–≤–µ—Ä
    pass

def run_tests():
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤"""
    print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤...")
    subprocess.run(["pytest", "tests/", "-v", "--cov=core", "--cov=models"])

def load_config():
    import yaml
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

if __name__ == "__main__":
    main()
```

3. Makefile –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞:
```makefile
.PHONY: install run test clean docker help

help:
	@echo "–î–û–ü–†–û–° MVP 2.0 - –ö–æ–º–∞–Ω–¥—ã:"
	@echo "  make install  - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"
	@echo "  make run      - –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"
	@echo "  make test     - –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤"
	@echo "  make docker   - –°–±–æ—Ä–∫–∞ Docker –æ–±—Ä–∞–∑–∞"
	@echo "  make clean    - –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∏ –ª–æ–≥–æ–≤"

install:
	python setup.py

run:
	python run.py --mode web

run-debug:
	python run.py --mode web --debug

test:
	python run.py --test

docker:
	docker build -t dopros-mvp:2.0.0 .

docker-run:
	docker-compose up -d

clean:
	rm -rf storage/cache/*
	rm -rf logs/*
	rm -rf __pycache__
	find . -type d -name "__pycache__" -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete

benchmark:
	python tests/benchmark.py

format:
	black core/ models/ utils/ integrations/
	isort core/ models/ utils/ integrations/

lint:
	pylint core/ models/ utils/ integrations/
	mypy core/ models/ utils/ integrations/
```
```

## üèÅ –§–ò–ù–ê–õ–¨–ù–´–ô –ß–ï–ö–õ–ò–°–¢

### –ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:
- [ ] –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
- [ ] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
- [ ] –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å .env —Å API –∫–ª—é—á–∞–º–∏

### –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞:
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫–æ–¥–∞
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Å—Ç—ã
- [ ] –£–±–µ–¥–∏—Ç—å—Å—è –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ø—Ä–æ—â–µ–Ω–∏–π
- [ ] –ó–∞–∫–æ–º–º–∏—Ç–∏—Ç—å —Ä–∞–±–æ—á—É—é –≤–µ—Ä—Å–∏—é

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:
- [ ] YOLO11 —Ä–∞–±–æ—Ç–∞–µ—Ç —Å GPU –∏ CPU
- [ ] DeepFace fallback —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] FFmpeg –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ
- [ ] OpenAI API –¥–æ—Å—Ç—É–ø–µ–Ω
- [ ] –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —Ä–∞–±–æ—Ç–∞—é—Ç
- [ ] –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
- [ ] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è
- [ ] –í—Å–µ 5 —Ç–∏–ø–æ–≤ –æ—Ç—á–µ—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è
- [ ] Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ–Ω
- [ ] Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

### –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:
- [ ] –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–º–æ –≤–∏–¥–µ–æ –æ—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞
- [ ] –í—Å–µ –æ—Ç—á–µ—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ –≤ –ª–æ–≥–∞—Ö
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–¥—É
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —É—Å–ø–µ—à–Ω–æ

## ‚ö†Ô∏è –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï

**–ù–ò–ö–ê–ö–ò–• –£–ü–†–û–©–ï–ù–ò–ô!** –ö–∞–∂–¥—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ü–û–õ–ù–û–°–¢–¨–Æ —Å–æ –≤—Å–µ–º–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏. –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –∏—Å–ø—Ä–∞–≤–ª—è–π, –Ω–æ –ù–ï —É–¥–∞–ª—è–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª.

**–ö–û–ú–ú–ò–¢–¨ –ß–ê–°–¢–û!** –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ –¥–µ–ª–∞–π –∫–æ–º–º–∏—Ç —Å –ø–æ–Ω—è—Ç–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.

**–¢–ï–°–¢–ò–†–£–ô –í–°–Å!** –ù–µ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–º–ø—Ç—É –ø–æ–∫–∞ —Ç–µ–∫—É—â–∏–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é.

–£—Å–ø–µ—Ö–æ–≤ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏! üöÄ